<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Rat-AI-touille: Enhancing Multi-Agent Collaboration in Overcooked-AI with Communication.">
  <meta name="keywords" content="Rat-AI-touille, Overcooked-AI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Rat-AI-touille: Enhancing Multi-Agent Collaboration in Overcooked-AI with Communication</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- MathJax for LaTeX-style equations -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Rat-AI-touille: Enhancing Multi-Agent Collaboration in Overcooked-AI with Communication</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/brianmunozc/">Brian Munoz Calonge</a>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/beatricelimlk/">Beatrice Lim</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Stanford University</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="has-text-centered">
        <img id="teaser" src="./static/images/layouts.gif" alt="Project teaser" height="100%">
      </div>
      <h2 class="subtitle has-text-centered" style="font-size: 0.9rem;">
        From left to right: Cramped Room, Asymmetric Advantages, Coordination Ring, Forced
        Coordination, Counter Circuit. Original layouts from Overcooked-AI<a href="#ref1">[1]</a>.
      </h2>
    </div>
  </div>
</section>

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- Abstract. -->
<section class="section hero is-light" id="abstract">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This project investigates the impact of explicit verbal communication on multi-agent collaboration
            in Overcooked-AI, a simplified model of the popular game Overcooked that serves as a testbed for
            reinforcement learning under collaborative constraints. We extend the framework by incorporating
            agent communication, refining reward shaping, and evaluating the performance of self-play-trained
            agents using Proximal Policy Optimization (PPO) in one of the five available layouts of Overcooked-AI.
          </p>
          <p>
            Preliminary results suggest that while communication enhances task efficiency and overall performance,
            achieving multitasking and effective coordination requires further refinement of reward modeling to
            align incentives with desired behaviors. Performance is assessed using sparse rewards —a measure based
            on the number of dishes delivered during gameplay— within a fixed game horizon of 400 timesteps. Results
            are compared against findings from the foundational study that developed Overcooked-AI, demonstrating
            its utility as a benchmark for human-AI coordination.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section" id="baseline">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Baseline Performance</h2>
        <div class="columns is-centered is-vcentered">
          <div class="column has-text-centered">
            <figure class="image" style="height: 420px; margin: 0 auto;">
              <img src="./static/images/baseline.gif" alt="Baseline agent behavior" style="height: 95%; width: auto; object-fit: contain; margin: 0 auto;">
            </figure>
            <h2 class="subtitle has-text-centered" style="font-size: 0.9rem;">
              Behavior of baseline agents.
            </h2>
          </div>
          <div class="column has-text-centered">
            <figure class="image" style="height: 420px; margin: 0 auto;">
              <img src="./static/images/baseline_bar.png" alt="Baseline performance metrics" style="height: 95%; width: auto; object-fit: contain; margin: 0 auto;">
            </figure>
            <h2 class="subtitle has-text-centered" style="font-size: 0.9rem;">
              Baseline Performance.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="communication">
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h2 class="title is-3">Adding Communication to Improve Coordination</h2>
      <div class="content has-text-justified">
        <p>
          Effective coordination in multi-agent reinforcement learning (MARL) is often hindered by sparse rewards and partial observability.
          While implicit coordination via shared environment state can emerge through self-play <a href="#ref2">[2]</a>, explicit communication has been shown to accelerate convergence and improve performance in dynamic, collaborative tasks <a href="#ref3">[3]</a>.
        </p>
        <p>
          In this work, we incorporate a verbal communication action (e.g., <code>"Cook"</code>) into the policy learning framework, allowing agents to share intent and coordinate roles more effectively.
        </p>
        <p>
          The standard policy optimization objective is extended to include communicative signals:
        </p>
        <p>
          \[
            \pi^* = \arg\max_{\pi} \mathbb{E}_{\tau \sim \pi} \left[ \sum_{t=0}^{T} R(s_t, a_t, m_t) \right]
          \]
        </p>
        <p>
          Communication improves shared understanding by increasing mutual information between agents:
        </p>
        <p>
          \[
            \mathcal{I}(s_t^A; s_t^B \mid m_t) > \mathcal{I}(s_t^A; s_t^B)
          \]
        </p>
        <p>
          It also reduces the entropy of the joint policy, reflecting more confident and aligned decision-making:
        </p>
        <p>
          \[
            \mathcal{H}(\pi_{\text{comm}}) < \mathcal{H}(\pi_{\text{no-comm}})
          \]
        </p>
        <p>
          These theoretical motivations align with empirical results in Overcooked-AI, where communication-enhanced agents exhibited faster learning and more efficient task execution than baseline self-play agents.
        </p>

      </div>
    </div>
  </div>
</section>

<section class="section" id="PPO">
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h2 class="title is-3">Training Neural Network Policies with PPO and Agent Communication</h2>
      <div class="content has-text-justified">
        <p>
          We train agents using <strong>Reinforcement Learning</strong> with <strong>Proximal Policy Optimization (PPO)</strong>,
          a robust deep learning algorithm for policy optimization in dynamic environments. The policy is parameterized by a convolutional neural network
          and updated using gradients derived from agent-environment interactions.
        </p>
      
        <p>
          The figure below summarizes the reinforcement learning loop enhanced with communication:
        </p>
        <figure class="image" style="height: 240px; margin: 0 auto;">
          <img src="./static/images/PPO_comm_diagram.png"
               alt="Reinforcement Learning with Communication Diagram"
               style="height: 90%; width: auto; object-fit: contain; margin: 0 auto;">
        </figure>
      
        <p>
          The agent receives a state \(s_t\), selects an action \(a_t\) and optionally sends a message \(m_t\),
          receives a reward \(r_t\), and updates its policy via PPO:
        </p>
      
        <p>
          \[
            \theta \leftarrow \theta + \alpha \hat{g}_{PPO}(\theta)
          \]
        </p>
      </div>
    </div>
  </div>
</section>


<section class="section" id="Training">
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h2 class="title is-3">Faster Convergence during Training</h2>
      <div class="content has-text-justified">
        <p>
          We compare training performance of agents with and without communication in Overcooked-AI. Agents with explicit communication learn faster and achieve higher final rewards under sparse conditions, converging roughly twice as quickly as baselines and demonstrating improved sample efficiency.
        </p>

        <figure class="image" style="height: 400px; margin: 0 auto;">
          <img src="./static/images/Training_4.png" alt="Training Results"
               style="height: 100%; width: auto; object-fit: contain; margin: 0 auto;">
        </figure> 

        <p style="margin-top: 1em;">
          <em>Key takeaway:</em> Allowing agents to explicitly communicate task-relevant intent reduces coordination ambiguity, enabling more stable and faster learning.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section" id="results">
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h2 class="title is-3">Final Results</h2>
      <div class="columns is-centered is-vcentered">
        <div class="column has-text-centered">
          <figure class="image" style="height: 420px; width: 320px; margin: 0 auto;">
            <img src="./static/images/improvement.gif" alt="Baseline agent behavior" style="height: 90%; width: auto; object-fit: cover; margin: 0 auto;">
          </figure>
          <h2 class="subtitle has-text-centered" style="font-size: 0.9rem;">
            Explicit communication encourages agent to use the extra oven.
          </h2>
        </div>
        <div class="column has-text-centered">
          <figure class="image" style="height: 400px; width: 600px; margin: 0 auto;">
            <img src="./static/images/Performance.png" alt="Baseline performance metrics" style="height: 95%; width: auto; object-fit: cover; margin: 0 auto;">
          </figure>
          <h2 class="subtitle has-text-centered" style="font-size: 0.9rem;">
            Performance of baseline vs. modifications with communication.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">


      <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2>


        <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>

        <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>


    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>
-->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">References</h2>
    <!-- References -->
    <div id="refs" style="font-size: 0.95em; margin-top: 1.5em;">
      <ol>
        <li id="ref1">Human Compatible AI, "Overcooked-AI: A Benchmark Environment for Collaborative Multi-Agent Learning," GitHub repository. [Online]. Available: <a href="https://github.com/HumanCompatibleAI/overcooked_ai">https://github.com/HumanCompatibleAI/overcooked_ai</a></li>
        <li id="ref2">Carroll et al., "On the Utility of Learning about Humans for Human-AI Coordination," BAIR, 2019.</li>
        <li id="ref3">Che, Okamura, Sadigh, "Efficient and Trustworthy Social Navigation via Explicit and Implicit Robot–Human Communication," IEEE Transactions on Robotics, 2020.</li>
      </ol>
    </div>
  </div>
</section>




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            The source code for this website waas borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">here</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
